{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSEhcEI602Qp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    files = ['util.py',\n",
        "             'windows.py',\n",
        "             'models']\n",
        "\n",
        "    for file in files:\n",
        "        os.system('rm ./' + file)\n",
        "        os.system(\n",
        "            'wget -nv https://raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/' + file)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from numpy.random import seed\n",
        "\n",
        "# fix for 'package not found' when installing in Anaconda environment\n",
        "if 'google.colab' not in str(get_ipython()):\n",
        "    import pip\n",
        "    pip.main(['install', 'xgboost'])\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "from util import select_relevant_rows, select_attributes, read_movement_data, download_updated_mobility_data, download_updated_mobility_data, series_to_supervised, split_dates, save_config, load_config, plot_graphs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvGRdSjZ0UnP"
      },
      "outputs": [],
      "source": [
        "use_existing_config = True\n",
        "column_to_predict = 'terapia_intensiva'\n",
        "columns = ['nuovi_positivi', 'terapia_intensiva', 'deceduti']\n",
        "split_percent = 0.75\n",
        "region_focus = 'Emilia-Romagna'\n",
        "attribute_focus = 'denominazione_regione'\n",
        "n_futures = [1, 2, 7, 14]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH7mmQes02RO"
      },
      "outputs": [],
      "source": [
        "local_region_path = r'../COVID-19/dati-regioni/dpc-covid19-ita-regioni.csv'\n",
        "remote_region_path = r'https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/dati-regioni/dpc-covid19-ita-regioni.csv'\n",
        "\n",
        "regions_frame = pd.read_csv(remote_region_path)\n",
        "\n",
        "region_focus_data = select_relevant_rows(\n",
        "    regions_frame,\n",
        "    attribute_focus,\n",
        "    region_focus\n",
        ")\n",
        "\n",
        "frame_interesting_columns = select_attributes(region_focus_data, [\n",
        "    'data',\n",
        "    'ricoverati_con_sintomi',\n",
        "    'terapia_intensiva',\n",
        "    'totale_ospedalizzati',\n",
        "    'variazione_totale_positivi',\n",
        "    'nuovi_positivi',\n",
        "    'deceduti',\n",
        "    'tamponi',\n",
        "    'ingressi_terapia_intensiva'\n",
        "])\n",
        "\n",
        "frame_interesting_columns = pd.DataFrame(frame_interesting_columns)\n",
        "frame_interesting_columns['data'] = pd.to_datetime(\n",
        "    frame_interesting_columns['data'])\n",
        "frame_interesting_columns['data'] = frame_interesting_columns['data'].dt.strftime(\n",
        "    r'%Y-%m-%d')\n",
        "frame_interesting_columns = frame_interesting_columns.fillna(0)\n",
        "\n",
        "mobility_data_url = r'https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv'\n",
        "file_path = r'../Global_Mobility_Report.csv'\n",
        "mobility_data_zip_url = r'https://www.gstatic.com/covid19/mobility/Region_Mobility_Report_CSVs.zip'\n",
        "zip_path = r'../Region_Mobility_Report_CSVs.zip'\n",
        "region_mobility_path = r'../Region_Mobility_Report_CSVs'\n",
        "\n",
        "download_updated_mobility_data(\n",
        "    mobility_data_url,\n",
        "    file_path,\n",
        "    region_mobility_path,\n",
        "    mobility_data_zip_url,\n",
        "    zip_path\n",
        ")\n",
        "\n",
        "mobility_df = read_movement_data(\n",
        "    region_mobility_path,\n",
        "    'IT_Region_Mobility_Report',\n",
        "    region='Emilia-Romagna'\n",
        ")\n",
        "\n",
        "mobility_df = mobility_df[['date',\n",
        "                           'retail_and_recreation_percent_change_from_baseline',\n",
        "                           'grocery_and_pharmacy_percent_change_from_baseline',\n",
        "                           'parks_percent_change_from_baseline',\n",
        "                           'transit_stations_percent_change_from_baseline',\n",
        "                           'workplaces_percent_change_from_baseline',\n",
        "                           'residential_percent_change_from_baseline']].fillna(0)\n",
        "\n",
        "frame_interesting_columns.rename(columns={'data': 'date'}, inplace=True)\n",
        "frame_interesting_columns.set_index('date', inplace=True)\n",
        "mobility_df.set_index('date', inplace=True)\n",
        "\n",
        "# revert cumulative data\n",
        "frame_interesting_columns['deceduti'] = frame_interesting_columns['deceduti'].diff(\n",
        ")\n",
        "frame_interesting_columns['tamponi'] = frame_interesting_columns['tamponi'].diff(\n",
        ")\n",
        "frame_interesting_columns.dropna(inplace=True)\n",
        "\n",
        "merged = pd.merge(\n",
        "    frame_interesting_columns,\n",
        "    mobility_df,\n",
        "    on='date'\n",
        ")\n",
        "\n",
        "merged = merged.fillna(0)\n",
        "merged.set_index(pd.DatetimeIndex(merged.index), inplace=True)\n",
        "\n",
        "# numpy seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Rygv_WVGIV5"
      },
      "outputs": [],
      "source": [
        "def split_series(series, n_past, n_future, arima=False):\n",
        "    X, y, X_indexes, y_indexes = list(), list(), list(), list()\n",
        "    index = np.array(series.index).reshape(series.values.shape[0], 1)\n",
        "    series = series.values\n",
        "\n",
        "    for window_start in range(len(series)):\n",
        "        past_end = window_start + n_past\n",
        "        future_end = past_end + n_future\n",
        "        if future_end > len(series):\n",
        "            break\n",
        "        start = 0 if arima == True else window_start\n",
        "\n",
        "        past, future = series[start:past_end,\n",
        "                              :], series[past_end:future_end, :]\n",
        "        past_index, future_index = index[start:past_end,\n",
        "                                         :], index[past_end:future_end, :]\n",
        "        X.append(past)\n",
        "        y.append(future)\n",
        "        X_indexes.append(past_index)\n",
        "        y_indexes.append(future_index)\n",
        "\n",
        "    return np.array(X), np.array(y), np.array(X_indexes), np.array(y_indexes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00PwH6fcy0UW"
      },
      "source": [
        "#LSTM Multi Output "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TATMB1MzQg-"
      },
      "outputs": [],
      "source": [
        "def define_compile_lstm(config, input_shape, n_future=7):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(config['input'], activation=config['activation'],\n",
        "                   input_shape=input_shape, return_sequences=True))\n",
        "    model.add(LSTM(config['hidden'], activation=config['activation'],\n",
        "                   return_sequences=False))\n",
        "    model.add(Dropout(config['dropout']))\n",
        "    model.add(Dense(n_future))\n",
        "    model.compile(optimizer=config['optimizer'], loss=config['loss'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def define_lstm_configs():\n",
        "    input = [32, 64, 128]\n",
        "    hidden = [32, 64, 128]\n",
        "    activation = ['relu']\n",
        "    dropout = [0.1, 0.2]\n",
        "    out = [1]\n",
        "    optimizer = ['adam']\n",
        "    loss = ['mae']\n",
        "    look_back = [28]\n",
        "\n",
        "    configs = []\n",
        "    keys = ['input', 'hidden', 'activation', 'dropout', 'out',\n",
        "            'optimizer', 'loss', 'look_back']\n",
        "\n",
        "    for i in input:\n",
        "        for j in hidden:\n",
        "            for k in activation:\n",
        "                for l in dropout:\n",
        "                    for m in out:\n",
        "                        for n in optimizer:\n",
        "                            for o in loss:\n",
        "                                for p in look_back:\n",
        "                                        config = dict(\n",
        "                                            zip(keys, (i, j, k, l, m, n, o, p)))\n",
        "                                        configs.append(config)\n",
        "\n",
        "    return configs\n",
        "\n",
        "\n",
        "def execute_lstm(\n",
        "        dataframe, column_to_predict, config, split_percent=0.80, multi=False, n_future=7):\n",
        "    df = dataframe[column_to_predict].copy()\n",
        "\n",
        "    split = int(split_percent*len(df))\n",
        "\n",
        "    n_past = config['look_back']\n",
        "    n_features = 1\n",
        "\n",
        "    train, test = pd.DataFrame(df[:split]), pd.DataFrame(df[split:])\n",
        "\n",
        "    scalers = {}\n",
        "\n",
        "    for i in train.columns:\n",
        "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "        s_s = scaler.fit_transform(train[i].values.reshape(-1, 1))\n",
        "        s_s = np.reshape(s_s, len(s_s))\n",
        "        scalers['scaler_' + i] = scaler\n",
        "        train[i] = s_s\n",
        "\n",
        "    for i in test.columns:\n",
        "        scaler = scalers['scaler_'+i]\n",
        "        s_s = scaler.transform(test[i].values.reshape(-1, 1))\n",
        "        s_s = np.reshape(s_s, len(s_s))\n",
        "        scalers['scaler_'+i] = scaler\n",
        "        test[i] = s_s\n",
        "\n",
        "    X_train, y_train, X_train_indexes, y_train_indexes = split_series(\n",
        "        train, n_past, n_future)\n",
        "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n",
        "    y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))\n",
        "\n",
        "    X_test, y_test, X_test_indexes, y_test_indexes = split_series(\n",
        "        test, n_past, n_future)\n",
        "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n",
        "    y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], n_features))\n",
        "\n",
        "    model = define_compile_lstm(config, input_shape=(n_past,n_features), n_future=n_future)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train, epochs=50, validation_data=(X_test, y_test),\n",
        "        verbose=0, shuffle=False)\n",
        "\n",
        "    pred = model.predict(X_test)\n",
        "\n",
        "    pred = pred.reshape(pred.shape[0], pred.shape[1], 1)\n",
        "\n",
        "    for index, i in enumerate(train.columns):\n",
        "        scaler = scalers['scaler_'+i]\n",
        "\n",
        "        pred[:, :, index] = scaler.inverse_transform(pred[:, :, index])\n",
        "\n",
        "        y_train[:, :, index] = scaler.inverse_transform(y_train[:, :, index])\n",
        "        y_test[:, :, index] = scaler.inverse_transform(y_test[:, :, index])\n",
        "\n",
        "    df_results = []\n",
        "\n",
        "    for i in range(len(y_test)):\n",
        "        current = pd.DataFrame(\n",
        "            {'y_test':y_test[i].reshape(-1),\n",
        "            'pred':pred[i].reshape(-1),\n",
        "            'dates':y_test_indexes[i].reshape(-1)})\n",
        "        current.set_index('dates', inplace=True)\n",
        "        df_results.append(current)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for el in df_results:\n",
        "        error = mean_absolute_error(el['y_test'], el['pred'])\n",
        "        results[el.index[0]] = (error, el)\n",
        "\n",
        "    sorted_results = sorted(results.items(), key=lambda x: x[1][0])\n",
        "\n",
        "    return sorted_results\n",
        "\n",
        "\n",
        "def grid_search_lstm(\n",
        "        dataframe, column_to_predict, split_percent=0.80, multi=False, n_future=7):\n",
        "    configs = define_lstm_configs()\n",
        "    results = []\n",
        "\n",
        "    for config in configs:\n",
        "        sorted_results = execute_lstm(\n",
        "            dataframe, column_to_predict, config, split_percent=split_percent,\n",
        "            multi=multi, n_future=n_future)\n",
        "\n",
        "        results.append((np.mean(np.array(list(map(lambda x:x[1][0], sorted_results)))), config))\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "for n_future in n_futures:\n",
        "    for column_to_predict in columns:\n",
        "        config_path = region_focus + '_' + 'uni_lstm_config' + '_' + column_to_predict\n",
        "        config_path = config_path + '_' + str(n_future)\n",
        "        if use_existing_config:\n",
        "            if not os.path.isfile(config_path):\n",
        "                os.system('wget -nv https://raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/configs/' + config_path)\n",
        "            config = load_config(config_path)\n",
        "            sorted_results = execute_lstm(\n",
        "                frame_interesting_columns, column_to_predict=column_to_predict,\n",
        "                config=config, split_percent=split_percent, multi=False, n_future=n_future)\n",
        "            os.system('rm ' + config_path)\n",
        "        else:\n",
        "            results = grid_search_lstm(\n",
        "                frame_interesting_columns, column_to_predict, split_percent=split_percent,\n",
        "                multi=False, n_future=n_future)\n",
        "\n",
        "            results.sort()\n",
        "            config = results[0][-1]\n",
        "\n",
        "            save_config(config_path, config)\n",
        "\n",
        "            sorted_results = execute_lstm(\n",
        "                frame_interesting_columns, column_to_predict=column_to_predict,\n",
        "                config=config, split_percent=split_percent, multi=False, n_future=n_future)\n",
        "\n",
        "        print('Best Config')\n",
        "        print(config)\n",
        "\n",
        "        print(('Best MAE: ', sorted_results[0][1][0]))\n",
        "        print(('Average MAE: ', np.mean(np.array(list(map(lambda x:x[1][0], sorted_results))))))\n",
        "        pyplot.plot(sorted_results[0][1][1]['y_test'])\n",
        "        pyplot.plot(sorted_results[0][1][1]['pred'])\n",
        "        pyplot.title('best slot: ' + column_to_predict)\n",
        "        pyplot.legend(['real', 'pred'])\n",
        "        pyplot.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L-JIOEgzf59"
      },
      "source": [
        "#XGBoost Multi Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c-OJA5xhI9u"
      },
      "outputs": [],
      "source": [
        "def define_xgb_configs():\n",
        "    max_depth = [3, 6, 10]\n",
        "    learning_rate = [0.01, 0.05, 0.1]\n",
        "    n_estimators = [50, 100, 500, 1000]\n",
        "    colsample_bytree = [0.3, 0.7]\n",
        "    look_back = [28]\n",
        "    objectives = ['reg:squarederror']\n",
        "\n",
        "    configs = []\n",
        "    keys = ['max_depth', 'learning_rate', 'n_estimators', 'colsample_bytree',\n",
        "            'look_back', 'objective']\n",
        "\n",
        "    for i in max_depth:\n",
        "        for j in learning_rate:\n",
        "            for k in n_estimators:\n",
        "                for l in colsample_bytree:\n",
        "                    for m in look_back:\n",
        "                            for n in objectives:\n",
        "                                config = dict(\n",
        "                                    zip(keys, (i, j, k, l, m, n)))\n",
        "                            configs.append(config)\n",
        "\n",
        "    return configs\n",
        "\n",
        "\n",
        "def execute_xgb(\n",
        "        dataframe, column_to_predict, config, split_percent=0.80, n_future=7, multi=False):\n",
        "    df = dataframe[column_to_predict].copy()\n",
        "    split = int(split_percent*len(df))\n",
        "\n",
        "    n_past = config['look_back']\n",
        "    n_features = 1\n",
        "\n",
        "    train, test = pd.DataFrame(df[:split]), pd.DataFrame(df[split:])\n",
        "\n",
        "    scalers = {}\n",
        "\n",
        "    for i in train.columns:\n",
        "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "        s_s = scaler.fit_transform(train[i].values.reshape(-1, 1))\n",
        "        s_s = np.reshape(s_s, len(s_s))\n",
        "        scalers['scaler_' + i] = scaler\n",
        "        train[i] = s_s\n",
        "\n",
        "    for i in test.columns:\n",
        "        scaler = scalers['scaler_'+i]\n",
        "        s_s = scaler.transform(test[i].values.reshape(-1, 1))\n",
        "        s_s = np.reshape(s_s, len(s_s))\n",
        "        scalers['scaler_'+i] = scaler\n",
        "        test[i] = s_s\n",
        "\n",
        "    X_train, y_train, X_train_indexes, y_train_indexes = split_series(\n",
        "        train, n_past, n_future)\n",
        "\n",
        "    X_test, y_test, X_test_indexes, y_test_indexes = split_series(\n",
        "        test, n_past, n_future)\n",
        "\n",
        "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\n",
        "    y_train = y_train.reshape(y_train.shape[0], y_train.shape[1])\n",
        "    X_train_indexes = X_train_indexes.reshape(\n",
        "        X_train_indexes.shape[0], X_train_indexes.shape[1])\n",
        "    y_train_indexes = y_train_indexes.reshape(\n",
        "        y_train_indexes.shape[0], y_train_indexes.shape[1])\n",
        "\n",
        "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1])\n",
        "    y_test = y_test.reshape(y_test.shape[0], y_test.shape[1])\n",
        "    X_test_indexes = X_test_indexes.reshape(\n",
        "        X_test_indexes.shape[0], X_test_indexes.shape[1])\n",
        "    y_test_indexes = y_test_indexes.reshape(\n",
        "        y_test_indexes.shape[0], y_test_indexes.shape[1])\n",
        "\n",
        "    model = define_xgb(config)\n",
        "    warnings.filterwarnings(action='ignore', category=UserWarning)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    prediction = model.predict(X_test)  \n",
        "\n",
        "    prediction[:, :] = scaler.inverse_transform(prediction[:, :])\n",
        "    y_test[:, :] = scaler.inverse_transform(y_test[:, :])\n",
        "\n",
        "    df_results = []\n",
        "\n",
        "    for i in range(len(y_test)):\n",
        "        current = pd.DataFrame(\n",
        "            {'y_test':y_test[i].reshape(-1),\n",
        "            'pred':prediction[i].reshape(-1),\n",
        "            'dates':y_test_indexes[i].reshape(-1)})\n",
        "        current.set_index('dates', inplace=True)\n",
        "        df_results.append(current)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for el in df_results:\n",
        "        error = mean_absolute_error(el['y_test'], el['pred'])\n",
        "        results[el.index[0]] = (error, el)\n",
        "\n",
        "    sorted_results = sorted(results.items(), key=lambda x: x[1][0])\n",
        "\n",
        "    return sorted_results\n",
        "\n",
        "\n",
        "def grid_search_xgb(\n",
        "        dataframe, column_to_predict, split_percent=0.80, n_future=7, multi=False):\n",
        "    configs = define_xgb_configs()\n",
        "    results = []\n",
        "\n",
        "    for config in configs:\n",
        "        sorted_results = execute_xgb(\n",
        "            dataframe, column_to_predict, config, split_percent=split_percent,\n",
        "            multi=multi, n_future=n_future)\n",
        "\n",
        "        results.append((np.mean(np.array(list(map(lambda x:x[1][0], sorted_results)))), config))\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def define_xgb(config):\n",
        "    return MultiOutputRegressor(XGBRegressor(**config, verbosity=0))\n",
        "\n",
        "\n",
        "for n_future in n_futures:\n",
        "    for column_to_predict in columns:\n",
        "        config_path = region_focus + '_' + 'uni_xgb_config' + '_' + column_to_predict\n",
        "        config_path = config_path + '_' + str(n_future)\n",
        "        if use_existing_config:\n",
        "            if not os.path.isfile(config_path):\n",
        "                os.system('wget -nv https://raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/configs/' + config_path)\n",
        "            config = load_config(config_path)\n",
        "            sorted_results = execute_xgb(\n",
        "                frame_interesting_columns, split_percent=split_percent, config=config,\n",
        "                column_to_predict=column_to_predict, multi=False, n_future=n_future)\n",
        "            os.system('rm ' + config_path)\n",
        "        else:\n",
        "            results = grid_search_xgb(\n",
        "                frame_interesting_columns, split_percent=split_percent,\n",
        "                column_to_predict=column_to_predict, multi=False)\n",
        "\n",
        "            results.sort(key=lambda tup: tup[0])\n",
        "\n",
        "            config = results[0][-1]\n",
        "\n",
        "            save_config(config_path, config)\n",
        "\n",
        "            sorted_results = execute_xgb(\n",
        "                frame_interesting_columns, split_percent=split_percent, config=config,\n",
        "                column_to_predict=column_to_predict, multi=False, n_future=n_future)\n",
        "\n",
        "        print('Best Config')\n",
        "        print(config)\n",
        "\n",
        "        print(('Best MAE: ', sorted_results[0][1][0]))\n",
        "        print(('Average MAE: ', np.mean(\n",
        "            np.array(list(map(lambda x:x[1][0], sorted_results))))))\n",
        "        pyplot.plot(sorted_results[0][1][1]['y_test'])\n",
        "        pyplot.plot(sorted_results[0][1][1]['pred'])\n",
        "        pyplot.title('best slot: ' + column_to_predict)\n",
        "        pyplot.legend(['real', 'pred'])\n",
        "        pyplot.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ARIMA Multi Output"
      ],
      "metadata": {
        "id": "EzFiOyH1wsBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_percent = 0.95\n",
        "\n",
        "def execute_arima(dataframe, order, column_to_predict, split_percent, n_future=7):\n",
        "    df = dataframe[column_to_predict].copy()\n",
        "    split = int(split_percent*len(df))\n",
        "\n",
        "    n_past = 14\n",
        "    n_features = 1\n",
        "\n",
        "    train, test = pd.DataFrame(df[:split]), pd.DataFrame(df[split:])\n",
        "\n",
        "    scalers = {}\n",
        "\n",
        "    for i in train.columns:\n",
        "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "        s_s = scaler.fit_transform(train[i].values.reshape(-1, 1))\n",
        "        s_s = np.reshape(s_s, len(s_s))\n",
        "        scalers['scaler_' + i] = scaler\n",
        "        train[i] = s_s\n",
        "\n",
        "    for i in test.columns:\n",
        "        scaler = scalers['scaler_'+i]\n",
        "        s_s = scaler.transform(test[i].values.reshape(-1, 1))\n",
        "        s_s = np.reshape(s_s, len(s_s))\n",
        "        scalers['scaler_'+i] = scaler\n",
        "        test[i] = s_s\n",
        "\n",
        "    X_train, y_train, X_train_indexes, y_train_indexes = split_series(\n",
        "        train, n_past, n_future, arima=True)\n",
        "\n",
        "    X_test, y_test, X_test_indexes, y_test_indexes = split_series(\n",
        "        test, n_past, n_future, arima=True)\n",
        "    \n",
        "    df_results = []\n",
        "\n",
        "    history = [x for x in train.values]\n",
        "\n",
        "    for i in range(len(X_test)):\n",
        "        current_history = np.array(history).reshape(-1)\n",
        "        current_history = np.append(current_history, X_test[i].reshape(-1))\n",
        "\n",
        "        model = ARIMA(current_history, order=order)\n",
        "        model_fitted = model.fit()\n",
        "        prediction = model_fitted.forecast(n_future)[0]\n",
        "\n",
        "        prediction = scaler.inverse_transform(prediction.reshape(-1,1))\n",
        "        y_test[i] = scaler.inverse_transform(y_test[i])\n",
        "\n",
        "        current = pd.DataFrame(\n",
        "            {'y_test':y_test[i].reshape(-1),\n",
        "            'pred':prediction.reshape(-1),\n",
        "            'dates':y_test_indexes[i].reshape(-1)})\n",
        "\n",
        "        current.set_index('dates', inplace=True)\n",
        "        \n",
        "        df_results.append(current)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for el in df_results:\n",
        "        error = mean_absolute_error(el['y_test'], el['pred'])\n",
        "        results[el.index[0]] = (error, el)\n",
        "\n",
        "    sorted_results = sorted(results.items(), key=lambda x: x[1][0])\n",
        "\n",
        "    return sorted_results\n",
        "\n",
        "\n",
        "def define_arima_configs():\n",
        "    p_values = [10]\n",
        "    d_values = [1]\n",
        "    q_values = [1]\n",
        "    return p_values, d_values, q_values\n",
        "\n",
        "\n",
        "def evaluate_models(dataframe, column_to_predict, split_percent, n_future=7):\n",
        "    p_values, d_values, q_values = define_arima_configs()\n",
        "    best_score, best_cfg = float(\"inf\"), None\n",
        "    for p in p_values:\n",
        "        for d in d_values:\n",
        "            for q in q_values:\n",
        "                order = (p, d, q)\n",
        "                sorted_results = execute_arima(\n",
        "                    dataframe, order, column_to_predict, split_percent, n_future)\n",
        "                avg_error = np.mean(\n",
        "                    np.array(list(map(lambda x:x[1][0], sorted_results))))\n",
        "                if avg_error < best_score:\n",
        "                    best_score, best_cfg = avg_error, order\n",
        "    return best_cfg\n",
        "\n",
        "\n",
        "for n_future in n_futures:\n",
        "    for column_to_predict in columns:\n",
        "        config_path = region_focus + '_' + 'arima_config' + '_' + column_to_predict\n",
        "        config_path = config_path + '_' + str(n_future)\n",
        "        if use_existing_config:\n",
        "            if not os.path.isfile(config_path):\n",
        "                os.system('wget -nv https://raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/configs/' + config_path)\n",
        "            config = load_config(config_path)\n",
        "            sorted_results = execute_arima(\n",
        "                frame_interesting_columns, config, column_to_predict, split_percent, n_future=n_future)\n",
        "            os.system('rm ' + config_path)\n",
        "        else:\n",
        "            config = evaluate_models(\n",
        "                frame_interesting_columns, column_to_predict, split_percent)\n",
        "\n",
        "            save_config(config_path, config)\n",
        "\n",
        "            sorted_results = execute_arima(\n",
        "                frame_interesting_columns, config, column_to_predict, split_percent, n_future=n_future)\n",
        "\n",
        "        print('Best Config')\n",
        "        print(config)\n",
        "\n",
        "        print(('Best MAE: ', sorted_results[0][1][0]))\n",
        "        print(('Average MAE: ', np.mean(\n",
        "            np.array(list(map(lambda x:x[1][0], sorted_results))))))\n",
        "        pyplot.plot(sorted_results[0][1][1]['y_test'])\n",
        "        pyplot.plot(sorted_results[0][1][1]['pred'])\n",
        "        pyplot.title('best slot: ' + column_to_predict)\n",
        "        pyplot.legend(['real', 'pred'])\n",
        "        pyplot.show()\n"
      ],
      "metadata": {
        "id": "GJxKkP_twqx6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "covid_multi_output.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b6e8a8e6cd5b0d8bd2b931e6e2bcfab8fa0bbcead3979137bf827a61abd923e3"
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 64-bit ('tf': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "metadata": {
      "interpreter": {
        "hash": "f85c0ae1067a86ad6a96b144378883e79fd1516474b579ba33ee3a7084540002"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}