{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSEhcEI602Qp",
        "outputId": "04fe8884-97db-46a0-fbb3-56fcec35cda7"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    !rm -r *\n",
        "    !wget -nv https://raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/util.py\n",
        "    !wget -nv https://raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/windows.py\n",
        "    !wget -nv https://raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/models.py\n",
        "    !wget -nv https://raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/configs/arima_config\n",
        "    !wget -nv https://raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/configs/multi_lstm_config\n",
        "    !wget -nv https://raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/configs/multi_xgb_config\n",
        "    !wget -nv https://raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/configs/multi_lstm_generator_config\n",
        "    !wget -nv https://raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/configs/uni_xgb_config\n",
        "    !wget -nv https://raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/configs/uni_lstm_config\n",
        "    !wget -nv https://raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/configs/uni_lstm_generator_config\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# fix for 'package not found' when installing in Anaconda environment\n",
        "if 'google.colab' not in str(get_ipython()):\n",
        "    import pip\n",
        "    pip.main(['install', 'xgboost'])\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from util import select_relevant_rows, select_attributes, read_movement_data, download_updated_mobility_data, download_updated_mobility_data, series_to_supervised, split_dates, save_config, load_config, plot_graphs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_laukLF02RI"
      },
      "source": [
        "# Data Acquisition and Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "jH7mmQes02RO",
        "outputId": "5883b04c-eb62-4d60-b361-955d941a5623"
      },
      "outputs": [],
      "source": [
        "local_region_path = r'../COVID-19/dati-regioni/dpc-covid19-ita-regioni.csv'\n",
        "remote_region_path = r'https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/dati-regioni/dpc-covid19-ita-regioni.csv'\n",
        "\n",
        "regions_frame = pd.read_csv(remote_region_path)\n",
        "\n",
        "region_focus = 'Emilia-Romagna'\n",
        "attribute_focus = 'denominazione_regione'\n",
        "\n",
        "region_focus_data = select_relevant_rows(\n",
        "    regions_frame,\n",
        "    attribute_focus,\n",
        "    region_focus\n",
        ")\n",
        "\n",
        "frame_interesting_columns = select_attributes(region_focus_data, [\n",
        "    'data',\n",
        "    'ricoverati_con_sintomi',\n",
        "    'terapia_intensiva',\n",
        "    'totale_ospedalizzati',\n",
        "    'variazione_totale_positivi',\n",
        "    'nuovi_positivi',\n",
        "    'deceduti',\n",
        "    'tamponi',\n",
        "    'ingressi_terapia_intensiva'\n",
        "])\n",
        "\n",
        "frame_interesting_columns = pd.DataFrame(frame_interesting_columns)\n",
        "frame_interesting_columns['data'] = pd.to_datetime(\n",
        "    frame_interesting_columns['data'])\n",
        "frame_interesting_columns['data'] = frame_interesting_columns['data'].dt.strftime(\n",
        "    r'%Y-%m-%d')\n",
        "frame_interesting_columns = frame_interesting_columns.fillna(0)\n",
        "\n",
        "mobility_data_url = r'https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv'\n",
        "file_path = r'../Global_Mobility_Report.csv'\n",
        "mobility_data_zip_url = r'https://www.gstatic.com/covid19/mobility/Region_Mobility_Report_CSVs.zip'\n",
        "zip_path = r'../Region_Mobility_Report_CSVs.zip'\n",
        "region_mobility_path = r'../Region_Mobility_Report_CSVs'\n",
        "\n",
        "download_updated_mobility_data(\n",
        "    mobility_data_url,\n",
        "    file_path,\n",
        "    region_mobility_path,\n",
        "    mobility_data_zip_url,\n",
        "    zip_path\n",
        ")\n",
        "\n",
        "mobility_df = read_movement_data(\n",
        "    region_mobility_path,\n",
        "    'IT_Region_Mobility_Report',\n",
        "    region='Emilia-Romagna'\n",
        ")\n",
        "\n",
        "mobility_df = mobility_df[['date',\n",
        "                           'retail_and_recreation_percent_change_from_baseline',\n",
        "                           'grocery_and_pharmacy_percent_change_from_baseline',\n",
        "                           'parks_percent_change_from_baseline',\n",
        "                           'transit_stations_percent_change_from_baseline',\n",
        "                           'workplaces_percent_change_from_baseline',\n",
        "                           'residential_percent_change_from_baseline']].fillna(0)\n",
        "\n",
        "frame_interesting_columns.rename(columns={'data': 'date'}, inplace=True)\n",
        "frame_interesting_columns.set_index('date', inplace=True)\n",
        "mobility_df.set_index('date', inplace=True)\n",
        "\n",
        "# revert cumulative data\n",
        "frame_interesting_columns['deceduti'] = frame_interesting_columns['deceduti'].diff(\n",
        ")\n",
        "frame_interesting_columns['tamponi'] = frame_interesting_columns['tamponi'].diff(\n",
        ")\n",
        "frame_interesting_columns.dropna(inplace=True)\n",
        "\n",
        "merged = pd.merge(\n",
        "    frame_interesting_columns,\n",
        "    mobility_df,\n",
        "    on='date'\n",
        ")\n",
        "\n",
        "merged = merged.fillna(0)\n",
        "merged.set_index(pd.DatetimeIndex(merged.index), inplace=True)\n",
        "\n",
        "merged.tail()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VqNVQUy802R1",
        "outputId": "d16dbf7f-62db-409e-9448-a395ef38dacb"
      },
      "outputs": [],
      "source": [
        "fig, axes = pyplot.subplots(nrows=4, ncols=2, figsize=(10, 8))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    data = np.array(\n",
        "        frame_interesting_columns[frame_interesting_columns.columns[i]])\n",
        "    ax.plot(pd.DataFrame(data))\n",
        "    ax.set_title(frame_interesting_columns.columns[i])\n",
        "    ax.plot()\n",
        "\n",
        "pyplot.tight_layout()\n",
        "\n",
        "fig, axes = pyplot.subplots(nrows=3, ncols=2, figsize=(10, 8))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    data = np.array(mobility_df[mobility_df.columns[i]])\n",
        "    ax.plot(pd.DataFrame(data))\n",
        "    ax.set_title(mobility_df.columns[i])\n",
        "    ax.plot()\n",
        "\n",
        "pyplot.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyy2a6kjj-rw"
      },
      "outputs": [],
      "source": [
        "use_existing_config = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA6MV9wO02SL"
      },
      "source": [
        "# Univariate XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61TluCEU02SN"
      },
      "outputs": [],
      "source": [
        "def define_xgb_configs():\n",
        "    max_depth = [3, 6, 10, 20]\n",
        "    learning_rate = [0.01, 0.05, 0.1, 0.5]\n",
        "    n_estimators = [50, 100, 500, 1000, 5000]\n",
        "    colsample_bytree = [0.3, 0.7]\n",
        "    look_back = [1, 2, 4, 7]\n",
        "    n_future = [1], \n",
        "    objectives = ['reg:squarederror']\n",
        "\n",
        "    configs = []\n",
        "    keys = ['max_depth', 'learning_rate', 'n_estimators', 'colsample_bytree',\n",
        "            'look_back', 'n_future', 'objective']\n",
        "\n",
        "    for i in max_depth:\n",
        "        for j in learning_rate:\n",
        "            for k in n_estimators:\n",
        "                for l in colsample_bytree:\n",
        "                    for m in look_back:\n",
        "                        for n in n_future:\n",
        "                            for o in objectives:\n",
        "                                config = dict(\n",
        "                                    zip(keys, (i, j, k, l, m, n, o)))\n",
        "                            configs.append(config)\n",
        "\n",
        "    return configs\n",
        "\n",
        "def execute_xgb(\n",
        "        dataframe, column_to_predict, config, split_percent=0.80, multi=False):\n",
        "    if multi:\n",
        "        frame = pd.DataFrame(dataframe)\n",
        "    else:\n",
        "        frame = pd.DataFrame(dataframe[column_to_predict])\n",
        "\n",
        "    index_to_predict = frame.columns.get_loc(column_to_predict)\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled = scaler.fit_transform(frame.to_numpy())\n",
        "\n",
        "    look_back = config['look_back']\n",
        "    split = int(split_percent*len(scaled))\n",
        "\n",
        "    train = scaled[:split]\n",
        "    test = scaled[split:]\n",
        "\n",
        "    train_reframed = series_to_supervised(\n",
        "        pd.DataFrame(train), window=look_back,\n",
        "        index_to_predict=index_to_predict).values\n",
        "    test_reframed = series_to_supervised(\n",
        "        pd.DataFrame(test), window=look_back,\n",
        "        index_to_predict=index_to_predict).values\n",
        "\n",
        "    train_X, train_y = train_reframed[:, :-1], train_reframed[:, -1]\n",
        "    test_X, test_y = test_reframed[:, :-1], test_reframed[:, -1]\n",
        "\n",
        "    model = define_xgb(config)\n",
        "    model.fit(train_X, train_y)\n",
        "\n",
        "    prediction = model.predict(test_X)\n",
        "\n",
        "    if multi:\n",
        "        prediction_copies = np.repeat(pd.DataFrame(\n",
        "            prediction).values, frame.shape[1], axis=-1)\n",
        "        test_copies = np.repeat(\n",
        "            pd.DataFrame(test_y).values, frame.shape[1], axis=-1)\n",
        "\n",
        "        prediction = scaler.inverse_transform(prediction_copies)[:, 0]\n",
        "        test_y = scaler.inverse_transform(test_copies)[:, 0]\n",
        "    else:\n",
        "        test_y = scaler.inverse_transform(test_y.reshape(-1, 1)).reshape(-1)\n",
        "        prediction = scaler.inverse_transform(\n",
        "            np.array(prediction).reshape(-1, 1)).reshape(-1)\n",
        "\n",
        "\n",
        "    error = mean_absolute_error(test_y, prediction)\n",
        "\n",
        "    return prediction, test_y, error\n",
        "\n",
        "\n",
        "def grid_search_xgb(\n",
        "        dataframe, column_to_predict, split_percent=0.80, multi=False):\n",
        "    configs = define_xgb_configs()\n",
        "    results = []\n",
        "\n",
        "    for config in configs:\n",
        "        _, _, error = execute_xgb(\n",
        "            dataframe, column_to_predict, config, split_percent=split_percent,\n",
        "            multi=multi)\n",
        "\n",
        "        results.append((error, config))\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def define_xgb(config):\n",
        "    model = XGBRegressor(**config)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6eyooBt45J7h",
        "outputId": "0b45fe57-01a1-421d-91db-3bb4c3e4d148"
      },
      "outputs": [],
      "source": [
        "config_path = 'uni_xgb_config'\n",
        "column_to_predict = 'nuovi_positivi'\n",
        "split_percent = 0.80\n",
        "\n",
        "if use_existing_config:\n",
        "    config = load_config(config_path)\n",
        "    prediction, test, error = execute_xgb(\n",
        "        frame_interesting_columns, split_percent=split_percent, config=config, \n",
        "        column_to_predict=column_to_predict, multi=False)\n",
        "    look_back = config['look_back']\n",
        "else:\n",
        "    results = grid_search_xgb(\n",
        "        frame_interesting_columns, split_percent=split_percent,\n",
        "        column_to_predict=column_to_predict, multi=False)\n",
        "\n",
        "    results.sort(key=lambda tup: tup[0])\n",
        "\n",
        "    config = results[0][-1]\n",
        "    look_back = config['look_back']\n",
        "\n",
        "    save_config(config_path, config)\n",
        "\n",
        "    prediction, test, error = execute_xgb(\n",
        "        frame_interesting_columns, split_percent=split_percent, config=config, \n",
        "        column_to_predict=column_to_predict, multi=False)\n",
        "\n",
        "    print('Best Config')\n",
        "    print(config)\n",
        "\n",
        "print('MAE: %.3f' % error)\n",
        "\n",
        "plot_graphs(\n",
        "    frame_interesting_columns, prediction, split_percent, column_to_predict,\n",
        "    look_back)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjnMCouq5J7k"
      },
      "source": [
        "# Multivariate XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "OohCQuyY5J7l",
        "outputId": "b54fdc7b-7962-4925-eed3-eca701068d82"
      },
      "outputs": [],
      "source": [
        "config_path = 'multi_xgb_config'\n",
        "column_to_predict = 'nuovi_positivi'\n",
        "split_percent = 0.80\n",
        "\n",
        "if use_existing_config:\n",
        "    config = load_config(config_path)\n",
        "    prediction, test, error = execute_xgb(\n",
        "        frame_interesting_columns, split_percent=split_percent, config=config, \n",
        "        column_to_predict=column_to_predict, multi=True)\n",
        "    look_back = config['look_back']\n",
        "else:\n",
        "    results = grid_search_xgb(\n",
        "        frame_interesting_columns, split_percent=split_percent,\n",
        "        column_to_predict=column_to_predict, multi=True)\n",
        "\n",
        "    results.sort(key=lambda tup: tup[0])\n",
        "\n",
        "    config = results[0][-1]\n",
        "    look_back = config['look_back']\n",
        "\n",
        "    save_config(config_path, config)\n",
        "\n",
        "    prediction, test, error = execute_xgb(\n",
        "        frame_interesting_columns, split_percent=split_percent, config=config, \n",
        "        column_to_predict=column_to_predict, multi=False)\n",
        "\n",
        "    print('Best Config')\n",
        "    print(config)\n",
        "\n",
        "print('MAE: %.3f' % error)\n",
        "\n",
        "plot_graphs(\n",
        "    frame_interesting_columns, prediction, split_percent, column_to_predict,\n",
        "    look_back)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JCQgslWo_F2"
      },
      "source": [
        "#ARIMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTTrdYt_pIIf"
      },
      "outputs": [],
      "source": [
        "def execute_arima(dataframe, order, column_to_predict, split_percent):\n",
        "    frame = pd.DataFrame(dataframe[column_to_predict])\n",
        "\n",
        "    split = int(split_percent*len(frame))\n",
        "\n",
        "    train = frame[:split].values\n",
        "    test = frame[split:].values\n",
        "\n",
        "    history = [x for x in train]\n",
        "    predictions = list()\n",
        "\n",
        "    for timestep in range(len(test)):\n",
        "        model = ARIMA(history, order=order)\n",
        "        model_fitted = model.fit()\n",
        "        prediction = model_fitted.forecast()[0]\n",
        "        predictions.append(prediction)\n",
        "        history.append(test[timestep])\n",
        "\n",
        "    predictions = np.array(predictions).reshape(-1)\n",
        "    test = np.array(test).reshape(-1)\n",
        "\n",
        "    error = mean_absolute_error(test, predictions)\n",
        "    return predictions, test, error\n",
        "\n",
        "\n",
        "def define_arima_configs():\n",
        "    p_values = [1, 8, 10]\n",
        "    d_values = range(1, 2)\n",
        "    q_values = range(1, 2)\n",
        "    return p_values, d_values, q_values\n",
        "\n",
        "\n",
        "def evaluate_models(dataframe, column_to_predict, split_percent):\n",
        "    p_values, d_values, q_values = define_arima_configs()\n",
        "    best_score, best_cfg = float(\"inf\"), None\n",
        "    for p in p_values:\n",
        "        for d in d_values:\n",
        "            for q in q_values:\n",
        "                order = (p, d, q)\n",
        "                _, _, error = execute_arima(\n",
        "                    dataframe, order, column_to_predict, split_percent)\n",
        "                if error < best_score:\n",
        "                    best_score, best_cfg = error, order\n",
        "    print('Best Model:%s MAE=%.3f' % (best_cfg, best_score))\n",
        "    return best_cfg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "STgtC99hDTQz",
        "outputId": "00254714-126c-45e8-de37-19a6f23209a8"
      },
      "outputs": [],
      "source": [
        "column_to_predict = 'nuovi_positivi'\n",
        "config_path = 'arima_config'\n",
        "split_percent = 0.80\n",
        "\n",
        "if use_existing_config:\n",
        "    config = load_config(config_path)\n",
        "    predictions, test, error = execute_arima(\n",
        "        frame_interesting_columns, config, column_to_predict, split_percent)\n",
        "else:\n",
        "    config = evaluate_models(\n",
        "        frame_interesting_columns, column_to_predict, split_percent) \n",
        "\n",
        "    save_config(config_path, config)\n",
        "\n",
        "    predictions, test, error = execute_arima(\n",
        "        frame_interesting_columns, config, column_to_predict, split_percent)\n",
        "\n",
        "print('MAE: %.3f' % error)\n",
        "\n",
        "plot_graphs(\n",
        "    frame_interesting_columns, predictions, split_percent, column_to_predict,\n",
        "    look_back=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYCaPqRwgkC_"
      },
      "outputs": [],
      "source": [
        "def define_compile_lstm(config, input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(config['input'], activation=config['activation'],\n",
        "                   input_shape=input_shape, return_sequences=True))\n",
        "    model.add(LSTM(config['hidden'], activation=config['activation'],\n",
        "                   return_sequences=False))\n",
        "    model.add(Dropout(config['dropout']))\n",
        "    model.add(Dense(config['out']))\n",
        "    model.compile(optimizer=config['optimizer'], loss=config['loss'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def define_lstm_configs():\n",
        "    input = [32, 64, 128]\n",
        "    hidden = [32, 64, 128]\n",
        "    activation = ['relu']\n",
        "    dropout = [0.1, 0.2]\n",
        "    out = [1]\n",
        "    optimizer = ['adam']\n",
        "    loss = ['mae']\n",
        "    look_back = [1, 2, 4, 7]\n",
        "    n_future = [1]\n",
        "\n",
        "    configs = []\n",
        "    keys = ['input', 'hidden', 'activation', 'dropout', 'out',\n",
        "            'optimizer', 'loss', 'look_back', 'n_future']\n",
        "\n",
        "    for i in input:\n",
        "        for j in hidden:\n",
        "            for k in activation:\n",
        "                for l in dropout:\n",
        "                    for m in out:\n",
        "                        for n in optimizer:\n",
        "                            for o in loss:\n",
        "                                for p in look_back:\n",
        "                                    for q in n_future:\n",
        "                                        config = dict(\n",
        "                                            zip(keys, (i, j, k, l, m, n, o, p, q)))\n",
        "                                        configs.append(config)\n",
        "\n",
        "    return configs\n",
        "\n",
        "\n",
        "def execute_lstm(\n",
        "        dataframe, column_to_predict, config, split_percent=0.80, multi=False):\n",
        "    if multi:\n",
        "        frame = pd.DataFrame(dataframe)\n",
        "    else:\n",
        "        frame = pd.DataFrame(dataframe[column_to_predict])\n",
        "\n",
        "    index_to_predict = frame.columns.get_loc(column_to_predict)\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled = scaler.fit_transform(frame.to_numpy())\n",
        "\n",
        "    look_back = config['look_back']\n",
        "    split = int(split_percent*len(scaled))\n",
        "\n",
        "    train = scaled[:split]\n",
        "    test = scaled[split:]\n",
        "\n",
        "    train_X, test_X = [], []\n",
        "    train_y, test_y = [], []\n",
        "\n",
        "    n_future = config['n_future']\n",
        "\n",
        "    if multi:\n",
        "        for i in range(look_back, len(train) - n_future + 1):\n",
        "            train_X.append(train[i - look_back:i, 0:train.shape[1]])\n",
        "            train_y.append(train[i + n_future - 1:i +\n",
        "                           n_future, index_to_predict])\n",
        "\n",
        "        for i in range(look_back, len(test) - n_future + 1):\n",
        "            test_X.append(test[i - look_back:i, 0:test.shape[1]])\n",
        "            test_y.append(test[i + n_future - 1:i +\n",
        "                          n_future, index_to_predict])\n",
        "\n",
        "        train_X, train_y = np.array(train_X), np.array(train_y)\n",
        "        test_X, test_y = np.array(test_X), np.array(test_y)\n",
        "    else:\n",
        "        train_reframed = series_to_supervised(\n",
        "            pd.DataFrame(train), look_back).values\n",
        "        test_reframed = series_to_supervised(\n",
        "            pd.DataFrame(test), look_back).values\n",
        "\n",
        "        train_X, train_y = train_reframed[:, :-1], train_reframed[:, -1]\n",
        "        test_X, test_y = test_reframed[:, :-1], test_reframed[:, -1]\n",
        "\n",
        "        train_X = train_X.reshape(\n",
        "            (train_X.shape[0], train_X.shape[1], len(frame.columns)))\n",
        "        test_X = test_X.reshape(\n",
        "            (test_X.shape[0], test_X.shape[1], len(frame.columns)))\n",
        "\n",
        "    input_shape = (look_back, len(frame.columns))\n",
        "\n",
        "    model = define_compile_lstm(config, input_shape=input_shape)\n",
        "\n",
        "    history = model.fit(\n",
        "        train_X, train_y, epochs=50, validation_data=(test_X, test_y),\n",
        "        verbose=0, shuffle=False)\n",
        "\n",
        "    prediction = model.predict(test_X)\n",
        "\n",
        "    if multi:\n",
        "        prediction_copies = np.repeat(prediction, frame.shape[1], axis=-1)\n",
        "        prediction_descaled = scaler.inverse_transform(prediction_copies)[:, 0]\n",
        "        prediction = prediction_descaled.reshape((-1))\n",
        "        test_y_copies = np.repeat(\n",
        "            pd.DataFrame(test_y).values, frame.shape[1], axis=-1)\n",
        "        test_y_descaled = scaler.inverse_transform(test_y_copies)[:, 0]\n",
        "        test_y = test_y_descaled.reshape((-1))\n",
        "    else:\n",
        "        prediction = scaler.inverse_transform(prediction).reshape(-1)\n",
        "        test_y = scaler.inverse_transform(\n",
        "            test_y.reshape(len(test_y),1)).reshape(-1)\n",
        "\n",
        "    error = mean_absolute_error(test_y, prediction)\n",
        "\n",
        "    return prediction, test_y, error, input_shape, history\n",
        "\n",
        "\n",
        "def grid_search_lstm(\n",
        "        dataframe, column_to_predict, split_percent=0.80, multi=False):\n",
        "    configs = define_lstm_configs()\n",
        "    results = []\n",
        "    for config in configs:\n",
        "        _, _, error, input_shape, _ = execute_lstm(\n",
        "            dataframe, column_to_predict, config, split_percent=split_percent,\n",
        "            multi=multi)\n",
        "\n",
        "        results.append((error, input_shape, config))\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def plot_loss(history):\n",
        "    pyplot.plot(history.history['loss'], label='Training loss')\n",
        "    pyplot.plot(history.history['val_loss'], label='Validation loss')\n",
        "    pyplot.legend()\n",
        "    pyplot.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMHz6797tYLk"
      },
      "outputs": [],
      "source": [
        "def execute_lstm_generator(\n",
        "        dataframe, column_to_predict, config, split_percent=0.80, multi=False):\n",
        "    if multi:\n",
        "        frame = pd.DataFrame(dataframe)\n",
        "    else:\n",
        "        frame = pd.DataFrame(dataframe[column_to_predict])\n",
        "\n",
        "    index_to_predict = frame.columns.get_loc(column_to_predict)\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled = scaler.fit_transform(frame.to_numpy())\n",
        "\n",
        "    look_back = config['look_back']\n",
        "    split = int(split_percent*len(scaled))\n",
        "\n",
        "    train = scaled[:split]\n",
        "    test = scaled[split:]\n",
        "\n",
        "    X = scaled[:][:]\n",
        "    y = scaled[:, index_to_predict][:]\n",
        "\n",
        "    train_X, test_X, train_y, test_y = train_test_split(\n",
        "        X, y, test_size=0.20, shuffle=False)\n",
        "    \n",
        "    input_shape = (look_back, len(frame.columns))\n",
        "\n",
        "    if multi:\n",
        "        train_generator = TimeseriesGenerator(\n",
        "            train_X, train_y, sampling_rate=1, length=look_back)\n",
        "        test_generator = TimeseriesGenerator(\n",
        "            test_X, test_y, sampling_rate=1, length=look_back)\n",
        "    else:\n",
        "        train_generator = TimeseriesGenerator(\n",
        "            train, train, length=look_back)\n",
        "        test_generator = TimeseriesGenerator(\n",
        "            test, test, length=look_back)\n",
        "\n",
        "    model = define_compile_lstm(config, input_shape=input_shape)\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator, epochs=50, validation_data=test_generator,\n",
        "        verbose=0, shuffle=False)\n",
        "\n",
        "    prediction = model.predict(test_generator)\n",
        "\n",
        "    if multi:\n",
        "        prediction_copies = np.repeat(prediction, frame.shape[1], axis=-1)\n",
        "        prediction_descaled = scaler.inverse_transform(prediction_copies)[:, 0]\n",
        "        prediction = prediction_descaled.reshape((-1))\n",
        "        test_copies = np.repeat(\n",
        "            pd.DataFrame(test_y).values, frame.shape[1], axis=-1)\n",
        "        test_descaled = scaler.inverse_transform(test_copies)[:, 0]\n",
        "        test = test_descaled.reshape((-1))\n",
        "    else:\n",
        "        prediction = scaler.inverse_transform(prediction).reshape(-1)\n",
        "        test = scaler.inverse_transform(\n",
        "            test.reshape(len(test),1)).reshape(-1)\n",
        "\n",
        "    test = test[look_back:]\n",
        "\n",
        "    error = mean_absolute_error(prediction, test)\n",
        "\n",
        "    return prediction, test, error, input_shape, history\n",
        "\n",
        "\n",
        "def grid_search_lstm_generator(\n",
        "        dataframe, column_to_predict, split_percent=0.80, multi=False):\n",
        "    configs = define_lstm_configs()\n",
        "    results = []\n",
        "    for config in configs:\n",
        "        _, _, error, input_shape, _ = execute_lstm_generator(\n",
        "            dataframe, column_to_predict, config, split_percent=split_percent,\n",
        "            multi=multi)\n",
        "\n",
        "        results.append((error, input_shape, config))\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lomTEbf-02Sh"
      },
      "source": [
        "# LSTM Univariate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PNmMeHi802Si",
        "outputId": "02ebd095-4246-46b2-8ae2-8f3908cefb89"
      },
      "outputs": [],
      "source": [
        "config_path = 'uni_lstm_config'\n",
        "column_to_predict = 'nuovi_positivi'\n",
        "split_percent = 0.80\n",
        "\n",
        "if use_existing_config:\n",
        "    config = load_config(config_path)\n",
        "    prediction, _, error, _, history = execute_lstm(\n",
        "        frame_interesting_columns, column_to_predict=column_to_predict,\n",
        "        config=config, split_percent=split_percent, multi=False)\n",
        "    look_back = config['look_back']\n",
        "else:\n",
        "    results = grid_search_lstm(\n",
        "        frame_interesting_columns, column_to_predict, split_percent=split_percent,\n",
        "        multi=False)\n",
        "\n",
        "    results.sort()\n",
        "    config = results[0][-1]\n",
        "    look_back = config['look_back']\n",
        "\n",
        "    save_config(config_path, config)\n",
        "    \n",
        "    prediction, _, error, _, history = execute_lstm(\n",
        "        frame_interesting_columns, column_to_predict=column_to_predict,\n",
        "        config=config, split_percent=split_percent, multi=False)\n",
        "\n",
        "plot_loss(history)\n",
        "\n",
        "print('MAE: %.3f' % error)\n",
        "\n",
        "plot_graphs(\n",
        "    frame_interesting_columns, prediction, split_percent, column_to_predict,\n",
        "    look_back)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4ZwyAH-coPq"
      },
      "source": [
        "#Univariate LSTM with TimeseriesGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6pfvZjsL2v_l",
        "outputId": "3b56ddaf-8009-442e-b660-b0997caa82b6"
      },
      "outputs": [],
      "source": [
        "config_path = 'uni_lstm_generator_config'\n",
        "column_to_predict = 'nuovi_positivi'\n",
        "split_percent = 0.80\n",
        "\n",
        "if use_existing_config:\n",
        "    config = load_config(config_path)\n",
        "    prediction, _, error, _, history = execute_lstm_generator(\n",
        "        frame_interesting_columns, column_to_predict=column_to_predict,\n",
        "        config=config, split_percent=split_percent, multi=False)\n",
        "    look_back = config['look_back']\n",
        "else:\n",
        "    results = grid_search_lstm_generator(\n",
        "        frame_interesting_columns, column_to_predict, split_percent=split_percent,\n",
        "        multi=False)\n",
        "\n",
        "    results.sort()\n",
        "    config = results[0][-1]\n",
        "    look_back = config['look_back']\n",
        "\n",
        "    save_config(config_path, config)\n",
        "    \n",
        "    prediction, _, error, _, history = execute_lstm_generator(\n",
        "        frame_interesting_columns, column_to_predict=column_to_predict,\n",
        "        config=config, split_percent=split_percent, multi=False)\n",
        "\n",
        "plot_loss(history)\n",
        "\n",
        "print('MAE: %.3f' % error)\n",
        "\n",
        "plot_graphs(\n",
        "    frame_interesting_columns, prediction, split_percent, column_to_predict,\n",
        "    look_back)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgb1Mg4StHbT"
      },
      "source": [
        "# Multivariate LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QHiFkUcG4ZZK",
        "outputId": "47d2a904-567a-446f-9485-6138fbdddf60"
      },
      "outputs": [],
      "source": [
        "config_path = 'multi_lstm_config'\n",
        "column_to_predict = 'nuovi_positivi'\n",
        "split_percent = 0.80\n",
        "\n",
        "if use_existing_config:\n",
        "    config = load_config(config_path)\n",
        "    prediction, _, error, _, history = execute_lstm(\n",
        "        frame_interesting_columns, column_to_predict=column_to_predict,\n",
        "        config=config, split_percent=split_percent, multi=True)\n",
        "    look_back = config['look_back']\n",
        "else:\n",
        "    results = grid_search_lstm(\n",
        "        frame_interesting_columns, column_to_predict, split_percent=split_percent,\n",
        "        multi=True)\n",
        "\n",
        "    results.sort()\n",
        "    config = results[0][-1]\n",
        "    look_back = config['look_back']\n",
        "\n",
        "    save_config(config_path, config)\n",
        "    \n",
        "    prediction, _, error, _, history = execute_lstm(\n",
        "        frame_interesting_columns, column_to_predict=column_to_predict,\n",
        "        config=config, split_percent=split_percent, multi=True)\n",
        "\n",
        "plot_loss(history)\n",
        "\n",
        "print('MAE: %.3f' % error)\n",
        "\n",
        "plot_graphs(\n",
        "    frame_interesting_columns, prediction, split_percent, column_to_predict,\n",
        "    look_back)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq4kerF4cyB3"
      },
      "source": [
        "# Multivariate LSTM with TimeseriesGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "FBBd_ev2t9-V",
        "outputId": "6706afd6-9012-429b-9340-8201c0533617"
      },
      "outputs": [],
      "source": [
        "config_path = 'multi_lstm_generator_config'\n",
        "column_to_predict = 'nuovi_positivi'\n",
        "split_percent = 0.80\n",
        "\n",
        "if use_existing_config:\n",
        "    config = load_config(config_path)\n",
        "    prediction, _, error, _, history = execute_lstm_generator(\n",
        "        frame_interesting_columns, column_to_predict=column_to_predict,\n",
        "        config=config, split_percent=split_percent, multi=True)\n",
        "    look_back = config['look_back']\n",
        "else:\n",
        "    results = grid_search_lstm_generator(\n",
        "        frame_interesting_columns, column_to_predict, split_percent=split_percent,\n",
        "        multi=True)\n",
        "\n",
        "    results.sort()\n",
        "    config = results[0][-1]\n",
        "    look_back = config['look_back']\n",
        "\n",
        "    save_config(config_path, config)\n",
        "    \n",
        "    prediction, _, error, _, history = execute_lstm_generator(\n",
        "        frame_interesting_columns, column_to_predict=column_to_predict,\n",
        "        config=config, split_percent=split_percent, multi=True)\n",
        "\n",
        "plot_loss(history)\n",
        "\n",
        "print('MAE: %.3f' % error)\n",
        "\n",
        "plot_graphs(\n",
        "    frame_interesting_columns, prediction, split_percent, column_to_predict,\n",
        "    look_back)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "covid_forecasting.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b6e8a8e6cd5b0d8bd2b931e6e2bcfab8fa0bbcead3979137bf827a61abd923e3"
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 64-bit ('tf': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "metadata": {
      "interpreter": {
        "hash": "f85c0ae1067a86ad6a96b144378883e79fd1516474b579ba33ee3a7084540002"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
