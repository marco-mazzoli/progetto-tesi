{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSEhcEI602Qp",
        "outputId": "f3875a78-8364-41b0-996b-6b7e468c299c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# fix for 'package not found' when installing in Anaconda environment\n",
        "if 'google.colab' not in str(get_ipython()):\n",
        "    import pip\n",
        "    pip.main(['install', 'xgboost'])\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    !rm util.py\n",
        "    !rm window.py\n",
        "    !rm models.py\n",
        "    !wget https: // raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/util.py\n",
        "    !wget https: // raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/windows.py\n",
        "    !wget https: // raw.githubusercontent.com/marco-mazzoli/progetto-tesi/master/models.py\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from util import select_relevant_rows, select_attributes, read_movement_data, download_updated_mobility_data, download_updated_mobility_data, series_to_supervised"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_laukLF02RI"
      },
      "source": [
        "# Data Acquisition and Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH7mmQes02RO"
      },
      "outputs": [],
      "source": [
        "local_region_path = r'../COVID-19/dati-regioni/dpc-covid19-ita-regioni.csv'\n",
        "remote_region_path = r'https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/dati-regioni/dpc-covid19-ita-regioni.csv'\n",
        "\n",
        "regions_frame = pd.read_csv(remote_region_path)\n",
        "\n",
        "region_focus = 'Emilia-Romagna'\n",
        "attribute_focus = 'denominazione_regione'\n",
        "\n",
        "region_focus_data = select_relevant_rows(\n",
        "    regions_frame,\n",
        "    attribute_focus,\n",
        "    region_focus\n",
        ")\n",
        "\n",
        "frame_interesting_columns = select_attributes(region_focus_data, [\n",
        "    'data',\n",
        "    'ricoverati_con_sintomi',\n",
        "    'terapia_intensiva',\n",
        "    'totale_ospedalizzati',\n",
        "    'variazione_totale_positivi',\n",
        "    'nuovi_positivi',\n",
        "    'deceduti',\n",
        "    'tamponi',\n",
        "    'ingressi_terapia_intensiva'\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "Kd6Ufo-U02Ra",
        "outputId": "0bf72d58-dd1c-490d-b2e7-c61774d8d3f2"
      },
      "outputs": [],
      "source": [
        "frame_interesting_columns.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyOjvvC402Rb",
        "outputId": "d4d08444-f0e0-4231-aba5-235808e374bf"
      },
      "outputs": [],
      "source": [
        "frame_interesting_columns = pd.DataFrame(frame_interesting_columns)\n",
        "frame_interesting_columns['data'] = pd.to_datetime(\n",
        "    frame_interesting_columns['data'])\n",
        "frame_interesting_columns['data'] = frame_interesting_columns['data'].dt.strftime(\n",
        "    r'%Y-%m-%d')\n",
        "frame_interesting_columns = frame_interesting_columns.fillna(0)\n",
        "\n",
        "mobility_data_url = r'https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv'\n",
        "file_path = r'../Global_Mobility_Report.csv'\n",
        "mobility_data_zip_url = r'https://www.gstatic.com/covid19/mobility/Region_Mobility_Report_CSVs.zip'\n",
        "zip_path = r'../Region_Mobility_Report_CSVs.zip'\n",
        "region_mobility_path = r'../Region_Mobility_Report_CSVs'\n",
        "\n",
        "download_updated_mobility_data(\n",
        "    mobility_data_url,\n",
        "    file_path,\n",
        "    region_mobility_path,\n",
        "    mobility_data_zip_url,\n",
        "    zip_path\n",
        ")\n",
        "\n",
        "mobility_df = read_movement_data(\n",
        "    region_mobility_path,\n",
        "    'IT_Region_Mobility_Report',\n",
        "    region='Emilia-Romagna'\n",
        ")\n",
        "\n",
        "mobility_df = mobility_df[['date',\n",
        "                           'retail_and_recreation_percent_change_from_baseline',\n",
        "                           'grocery_and_pharmacy_percent_change_from_baseline',\n",
        "                           'parks_percent_change_from_baseline',\n",
        "                           'transit_stations_percent_change_from_baseline',\n",
        "                           'workplaces_percent_change_from_baseline',\n",
        "                           'residential_percent_change_from_baseline']].fillna(0)\n",
        "\n",
        "frame_interesting_columns.rename(columns={'data': 'date'}, inplace=True)\n",
        "frame_interesting_columns.set_index('date', inplace=True)\n",
        "mobility_df.set_index('date', inplace=True)\n",
        "merged = pd.merge(\n",
        "    frame_interesting_columns,\n",
        "    mobility_df,\n",
        "    on='date'\n",
        ")\n",
        "\n",
        "merged = merged.fillna(0)\n",
        "merged.set_index(pd.DatetimeIndex(merged.index), inplace=True)\n",
        "\n",
        "# revert cumulative data\n",
        "frame_interesting_columns['deceduti'] = frame_interesting_columns['deceduti'].diff()\n",
        "frame_interesting_columns['tamponi'] = frame_interesting_columns['tamponi'].diff()\n",
        "frame_interesting_columns.dropna(inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VqNVQUy802R1",
        "outputId": "6c7c6ef6-7c62-463f-a54c-9134a7ced92f"
      },
      "outputs": [],
      "source": [
        "fig, axes = pyplot.subplots(nrows=4, ncols=2, figsize=(10, 8))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    data = np.array(\n",
        "        frame_interesting_columns[frame_interesting_columns.columns[i]])\n",
        "    ax.plot(pd.DataFrame(data))\n",
        "    ax.set_title(frame_interesting_columns.columns[i])\n",
        "    ax.plot()\n",
        "\n",
        "pyplot.tight_layout()\n",
        "\n",
        "fig, axes = pyplot.subplots(nrows=3, ncols=2, figsize=(10, 8))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    data = np.array(mobility_df[mobility_df.columns[i]])\n",
        "    ax.plot(pd.DataFrame(data))\n",
        "    ax.set_title(mobility_df.columns[i])\n",
        "    ax.plot()\n",
        "\n",
        "pyplot.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA6MV9wO02SL"
      },
      "source": [
        "# Univariate XGBOOST walk forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61TluCEU02SN"
      },
      "outputs": [],
      "source": [
        "def split_for_testing(data, split_percent):\n",
        "    split = int(split_percent*len(data))\n",
        "    return data[:split, :], data[split:, :]\n",
        "\n",
        "\n",
        "def split_dates(data, split_percent, look_back=7):\n",
        "    split = int(split_percent*len(data))\n",
        "    date_train = data.index[:split]\n",
        "    date_test = data.index[split:]\n",
        "    date_prediction = data.index[split+look_back:]\n",
        "    return date_train, date_test, date_prediction\n",
        "\n",
        "\n",
        "def walk_forward_validation(data, split_percent):\n",
        "    predictions = list()\n",
        "    train, test = split_for_testing(data, split_percent)\n",
        "    history = [x for x in train]\n",
        "    for i in range(len(test)):\n",
        "        test_X, test_y = test[i, :-1], test[i, -1]\n",
        "        prediction = xgboost_forecast_retrain(history, test_X)\n",
        "        predictions.append(prediction)\n",
        "        history.append(test[i])\n",
        "    error = mean_absolute_error(test[:, -1], predictions)\n",
        "    return error, test[:, -1], predictions\n",
        "\n",
        "\n",
        "def xgboost_forecast_retrain(train, test_X):\n",
        "    train = np.ascontiguousarray(train)\n",
        "    test_X = np.ascontiguousarray(test_X)\n",
        "    train_X, train_y = train[:, :-1], train[:, -1]\n",
        "    model = XGBRegressor(objective='reg:squarederror', n_estimators=1000)\n",
        "    model.fit(train_X, train_y)\n",
        "    prediction = model.predict([test_X])\n",
        "    return prediction[0]\n",
        "\n",
        "def execute_xgboost(data, split_percent, params = {}):\n",
        "    train, test = split_for_testing(data, split_percent)\n",
        "    train_X, train_y = train[:,:-1], train[:, -1]\n",
        "    test_X, test_y = test[:,:-1], test[:, -1]\n",
        "    model = XGBRegressor(objective='reg:squarederror', **params)\n",
        "    model.fit(train_X, train_y)\n",
        "    prediction = model.predict(test_X)\n",
        "    error = mean_absolute_error(test_y, prediction)\n",
        "    return error, test_y, prediction\n",
        "\n",
        "\n",
        "def execute_xgboost_cv(data, split_percent, params):\n",
        "    train, test = split_for_testing(data, split_percent)\n",
        "    train_X, train_y = train[:,:-1], train[:, -1]\n",
        "    test_X, test_y = test[:,:-1], test[:, -1]\n",
        "    model = XGBRegressor(objective='reg:squarederror')\n",
        "    gscv = GridSearchCV(\n",
        "        estimator = model, \n",
        "        param_grid = params,\n",
        "        scoring = 'neg_mean_squared_error', \n",
        "        verbose = 0)\n",
        "    gscv.fit(train_X, train_y, verbose = 1)\n",
        "    return gscv.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "uIXBa8g302Sc",
        "outputId": "46e5ffe8-3b15-4088-f449-006fbe4cdb7d"
      },
      "outputs": [],
      "source": [
        "column_univariate = 'nuovi_positivi'\n",
        "df = pd.DataFrame(frame_interesting_columns[column_univariate])\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(df)\n",
        "\n",
        "split_percent = 0.80\n",
        "look_back = 7\n",
        "\n",
        "values = scaled\n",
        "\n",
        "reframed = series_to_supervised(pd.DataFrame(values), window=look_back)\n",
        "# remove first look_back values\n",
        "values = values[look_back:]\n",
        "split = int(split_percent*len(values))\n",
        "df = df[look_back:]\n",
        "date_train, date_test, date_prediction = split_dates(\n",
        "    df, split_percent, look_back=0)\n",
        "\n",
        "train = df[:split].values.reshape(-1)\n",
        "test_original = df[split:].values.reshape(-1)\n",
        "\n",
        "mae, test, prediction = walk_forward_validation(\n",
        "    reframed.values, split_percent=split_percent)\n",
        "\n",
        "test = scaler.inverse_transform(test.reshape(-1, 1)).reshape(-1)\n",
        "prediction = scaler.inverse_transform(\n",
        "    np.array(prediction).reshape(-1, 1)).reshape(-1)\n",
        "\n",
        "print('MAE: %.3f' % mean_absolute_error(test_original, prediction))\n",
        "\n",
        "data_trace = go.Scatter(x=date_train, y=train, mode='lines', name='Data')\n",
        "prediction_trace = go.Scatter(\n",
        "    x=date_prediction, y=prediction, mode='lines', name='Prediction')\n",
        "truth_trace = go.Scatter(\n",
        "    x=date_test, y=test_original, mode='lines', name='Ground Truth')\n",
        "layout = go.Layout(title=\"nuovi_positivi\", xaxis={\n",
        "                   'title': \"Date\"}, yaxis={'title': \"nuovi_positivi\"})\n",
        "\n",
        "fig = go.Figure(data=[data_trace, prediction_trace,\n",
        "                truth_trace], layout=layout)\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOthyFO45J7h"
      },
      "source": [
        "# Univariate XGBoost no walk forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "6eyooBt45J7h",
        "outputId": "b9ec90c9-7b23-4884-e3c9-796cffce66a4"
      },
      "outputs": [],
      "source": [
        "column_univariate = 'nuovi_positivi'\n",
        "df = pd.DataFrame(frame_interesting_columns[column_univariate])\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(df)\n",
        "\n",
        "split_percent = 0.80\n",
        "look_back = 7\n",
        "\n",
        "values = scaled\n",
        "\n",
        "reframed = series_to_supervised(pd.DataFrame(values), window=look_back)\n",
        "# remove first look_back values\n",
        "values = values[look_back:]\n",
        "split = int(split_percent*len(values))\n",
        "df = df[look_back:]\n",
        "date_train, date_test, date_prediction = split_dates(\n",
        "    df, split_percent, look_back=0)\n",
        "\n",
        "train = df[:split].values.reshape(-1)\n",
        "test_original = df[split:].values.reshape(-1)\n",
        "\n",
        "params = {\n",
        "    'max_depth': [3, 6, 10, 20],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.5],\n",
        "    'n_estimators': [50, 100, 500, 1000, 5000],\n",
        "    'colsample_bytree': [0.3, 0.7]\n",
        "    }\n",
        "\n",
        "best_params = execute_xgboost_cv(\n",
        "    reframed.values, split_percent=split_percent, params=params)\n",
        "\n",
        "print(\"Best config: \")\n",
        "print(best_params)\n",
        "\n",
        "mae, test, prediction = execute_xgboost(\n",
        "    reframed.values, split_percent=split_percent, params=best_params)\n",
        "\n",
        "test = scaler.inverse_transform(test.reshape(-1, 1)).reshape(-1)\n",
        "prediction = scaler.inverse_transform(\n",
        "    np.array(prediction).reshape(-1, 1)).reshape(-1)\n",
        "\n",
        "print('MAE: %.3f' % mean_absolute_error(test_original, prediction))\n",
        "\n",
        "data_trace = go.Scatter(x=date_train, y=train, mode='lines', name='Data')\n",
        "prediction_trace = go.Scatter(\n",
        "    x=date_prediction, y=prediction, mode='lines', name='Prediction')\n",
        "truth_trace = go.Scatter(\n",
        "    x=date_test, y=test_original, mode='lines', name='Ground Truth')\n",
        "layout = go.Layout(title=\"nuovi_positivi\", xaxis={\n",
        "                   'title': \"Date\"}, yaxis={'title': \"nuovi_positivi\"})\n",
        "\n",
        "fig = go.Figure(data=[data_trace, prediction_trace,\n",
        "                truth_trace], layout=layout)\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfWiDt1Qv_Vp"
      },
      "source": [
        "# Multivariate XGBOOST walk forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "fiw6W--p5J7i",
        "outputId": "0c25e6e6-0513-46bd-b247-914ca373b1b5"
      },
      "outputs": [],
      "source": [
        "# df = pd.DataFrame(frame_interesting_columns.drop('tamponi', axis=1))\n",
        "df = frame_interesting_columns\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(df)\n",
        "\n",
        "column_to_predict = 'nuovi_positivi'\n",
        "index_to_predict = df.columns.get_loc(column_to_predict)\n",
        "\n",
        "values = scaled\n",
        "\n",
        "reframed = series_to_supervised(\n",
        "    pd.DataFrame(values), window=look_back, index_to_predict=index_to_predict)\n",
        "\n",
        "values = values[look_back:]\n",
        "df = df[look_back:]\n",
        "\n",
        "split_percent = 0.80\n",
        "split = int(split_percent*len(df))\n",
        "\n",
        "date_train, date_test, date_prediction = split_dates(\n",
        "    df, split_percent, look_back=0)\n",
        "\n",
        "train = df.values[:split, index_to_predict].reshape(-1)\n",
        "test_original = df.values[split:, index_to_predict].reshape(-1)\n",
        "\n",
        "mae, test, prediction = walk_forward_validation(\n",
        "    reframed.values, split_percent=split_percent)\n",
        "\n",
        "prediction_copies = np.repeat(pd.DataFrame(\n",
        "    prediction).values, df.shape[1], axis=-1)\n",
        "test_copies = np.repeat(pd.DataFrame(test).values, df.shape[1], axis=-1)\n",
        "\n",
        "prediction = scaler.inverse_transform(prediction_copies)[:, 0]\n",
        "test = scaler.inverse_transform(test_copies)[:, 0]\n",
        "\n",
        "print('MAE: %.3f' % mean_absolute_error(test_original, prediction))\n",
        "\n",
        "data_trace = go.Scatter(x=date_train, y=train, mode='lines', name='Data')\n",
        "prediction_trace = go.Scatter(\n",
        "    x=date_prediction, y=prediction, mode='lines', name='Prediction')\n",
        "truth_trace = go.Scatter(\n",
        "    x=date_test, y=test_original, mode='lines', name='Ground Truth')\n",
        "layout = go.Layout(title=\"nuovi_positivi\", xaxis={\n",
        "                   'title': \"Date\"}, yaxis={'title': \"nuovi_positivi\"})\n",
        "\n",
        "fig = go.Figure(data=[data_trace, prediction_trace,\n",
        "                truth_trace], layout=layout)\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjnMCouq5J7k"
      },
      "source": [
        "# Multivariate XGBOOST no walk forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OohCQuyY5J7l"
      },
      "outputs": [],
      "source": [
        "df = frame_interesting_columns\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(df)\n",
        "\n",
        "column_to_predict = 'nuovi_positivi'\n",
        "index_to_predict = df.columns.get_loc(column_to_predict)\n",
        "\n",
        "values = scaled\n",
        "\n",
        "reframed = series_to_supervised(\n",
        "    pd.DataFrame(values), window=look_back, index_to_predict=index_to_predict)\n",
        "\n",
        "values = values[look_back:]\n",
        "df = df[look_back:]\n",
        "\n",
        "split_percent = 0.80\n",
        "split = int(split_percent*len(df))\n",
        "\n",
        "date_train, date_test, date_prediction = split_dates(\n",
        "    df, split_percent, look_back=0)\n",
        "\n",
        "train = df.values[:split, index_to_predict].reshape(-1)\n",
        "test_original = df.values[split:, index_to_predict].reshape(-1)\n",
        "\n",
        "params = {\n",
        "    'max_depth': [3, 6, 10, 20],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.5],\n",
        "    'n_estimators': [50, 100, 500, 1000, 5000],\n",
        "    'colsample_bytree': [0.3, 0.7]\n",
        "    }\n",
        "\n",
        "best_params = execute_xgboost_cv(\n",
        "    reframed.values, split_percent=split_percent, params=params)\n",
        "\n",
        "print(\"Best config: \")\n",
        "print(best_params)\n",
        "\n",
        "mae, test, prediction = execute_xgboost(\n",
        "    reframed.values, split_percent=split_percent)\n",
        "\n",
        "prediction_copies = np.repeat(pd.DataFrame(\n",
        "    prediction).values, df.shape[1], axis=-1)\n",
        "test_copies = np.repeat(pd.DataFrame(test).values, df.shape[1], axis=-1)\n",
        "\n",
        "prediction = scaler.inverse_transform(prediction_copies)[:, 0]\n",
        "test = scaler.inverse_transform(test_copies)[:, 0]\n",
        "\n",
        "print('MAE: %.3f' % mean_absolute_error(test_original, prediction))\n",
        "\n",
        "data_trace = go.Scatter(x=date_train, y=train, mode='lines', name='Data')\n",
        "prediction_trace = go.Scatter(\n",
        "    x=date_prediction, y=prediction, mode='lines', name='Prediction')\n",
        "truth_trace = go.Scatter(\n",
        "    x=date_test, y=test_original, mode='lines', name='Ground Truth')\n",
        "layout = go.Layout(title=\"nuovi_positivi\", xaxis={\n",
        "                   'title': \"Date\"}, yaxis={'title': \"nuovi_positivi\"})\n",
        "\n",
        "fig = go.Figure(data=[data_trace, prediction_trace,\n",
        "                truth_trace], layout=layout)\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JCQgslWo_F2"
      },
      "source": [
        "#ARIMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTTrdYt_pIIf"
      },
      "outputs": [],
      "source": [
        "def execute_arima(data, order):\n",
        "    split_percent = 0.80\n",
        "    split = int(split_percent*len(data))\n",
        "    train = data[:split]\n",
        "    test = data[split:]\n",
        "    history = [x for x in train]\n",
        "    predictions = list()\n",
        "    for timestep in range(len(test)):\n",
        "        model = ARIMA(history, order=order)\n",
        "        model_fitted = model.fit()\n",
        "        prediction = model_fitted.forecast()[0]\n",
        "        predictions.append(prediction)\n",
        "        history.append(test[timestep])\n",
        "    error = mean_absolute_error(test, predictions)\n",
        "    return predictions, test, error\n",
        "\n",
        "\n",
        "def evaluate_models(data, p_values, q_values, d_values):\n",
        "    data = data.astype('float32')\n",
        "    best_score, best_cfg = float(\"inf\"), None\n",
        "    for p in p_values:\n",
        "        for d in d_values:\n",
        "            for q in q_values:\n",
        "                order = (p,d,q)\n",
        "                predictions, test, error = execute_arima(data, order)\n",
        "                if error < best_score:\n",
        "                    best_score, best_cfg = error, order\n",
        "    print('Best Model:%s MAE=%.3f' % (best_cfg, best_score))\n",
        "    return best_cfg\n",
        "\n",
        "\n",
        "def evaluate_models_mock(data, p_values, q_values, d_values):\n",
        "    return (10,1,1)\n",
        "\n",
        "column_univariate = 'nuovi_positivi'\n",
        "df = pd.DataFrame(frame_interesting_columns[column_univariate])\n",
        "\n",
        "split_percent = 0.80\n",
        "split = int(split_percent*len(df))\n",
        "\n",
        "train = df[:split].values\n",
        "test = df[split:].values\n",
        "p_values = [1, 8, 10]\n",
        "d_values = range(1, 2)\n",
        "q_values = range(1, 2)\n",
        "best_cfg = evaluate_models_mock(df.values, p_values, d_values, q_values) #10,1,1\n",
        "\n",
        "date_train, date_test, date_prediction = split_dates(\n",
        "    df, split_percent, look_back=0)\n",
        "\n",
        "predictions, test, error = execute_arima(df.values, best_cfg)\n",
        "\n",
        "predictions = np.array(predictions).reshape(-1)\n",
        "test = np.array(test).reshape(-1)\n",
        "\n",
        "print('Test mae: %.3f' % mean_absolute_error(test, predictions))\n",
        "\n",
        "data_trace = go.Scatter(\n",
        "    x=date_train, y=train.reshape(-1), mode='lines', name='Data')\n",
        "prediction_trace = go.Scatter(\n",
        "    x=date_test, y=predictions, mode='lines', name='Prediction')\n",
        "truth_trace = go.Scatter(\n",
        "    x=date_test, y=test, mode='lines', name='Ground Truth')\n",
        "layout = go.Layout(title=\"nuovi_positivi\", xaxis={\n",
        "                   'title': \"Date\"}, yaxis={'title': \"nuovi_positivi\"})\n",
        "\n",
        "fig = go.Figure(data=[data_trace, prediction_trace,\n",
        "                truth_trace], layout=layout)\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lomTEbf-02Sh"
      },
      "source": [
        "# LSTM Univariate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNmMeHi802Si"
      },
      "outputs": [],
      "source": [
        "column_univariate = 'nuovi_positivi'\n",
        "df = pd.DataFrame(frame_interesting_columns[column_univariate])\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(df)\n",
        "\n",
        "look_back = 7\n",
        "split_percent = 0.80\n",
        "split = int(split_percent*len(scaled))\n",
        "\n",
        "train = scaled[:split]\n",
        "test = scaled[split:]\n",
        "\n",
        "date_train = df.index[:split]\n",
        "date_test = df.index[split:]\n",
        "date_prediction = df.index[split+look_back:]\n",
        "\n",
        "train_reframed = series_to_supervised(pd.DataFrame(train), look_back).values\n",
        "test_reframed = series_to_supervised(pd.DataFrame(test), look_back).values\n",
        "\n",
        "train_X, train_y = train_reframed[:, :-1], train_reframed[:, -1]\n",
        "test_X, test_y = test_reframed[:, :-1], test_reframed[:, -1]\n",
        "\n",
        "train_X = train_X.reshape((train_X.shape[0], train_X.shape[1], 1))\n",
        "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], 1))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mae', optimizer='adam')\n",
        "\n",
        "history = model.fit(train_X, train_y, epochs=50,\n",
        "                    validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
        "\n",
        "pyplot.plot(history.history['loss'], label='Training loss')\n",
        "pyplot.plot(history.history['val_loss'], label='Validation loss')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "\n",
        "prediction = model.predict(test_X)\n",
        "\n",
        "train = scaler.inverse_transform(train).reshape(-1)\n",
        "test = scaler.inverse_transform(test).reshape(-1)\n",
        "prediction = scaler.inverse_transform(prediction).reshape(-1)\n",
        "\n",
        "print('MAE: %.3f' % mean_absolute_error(test[look_back:], prediction))\n",
        "\n",
        "data_trace = go.Scatter(x=date_train, y=train, mode='lines', name='Data')\n",
        "prediction_trace = go.Scatter(\n",
        "    x=date_prediction, y=prediction, mode='lines', name='Prediction')\n",
        "truth_trace = go.Scatter(\n",
        "    x=date_test, y=test, mode='lines', name='Ground Truth')\n",
        "layout = go.Layout(title=\"nuovi_positivi\", xaxis={\n",
        "                   'title': \"Date\"}, yaxis={'title': \"nuovi_positivi\"})\n",
        "\n",
        "fig = go.Figure(data=[data_trace, prediction_trace,\n",
        "                truth_trace], layout=layout)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4ZwyAH-coPq"
      },
      "source": [
        "#Univariate LSTM with TimeseriesGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pfvZjsL2v_l"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(frame_interesting_columns['nuovi_positivi'])\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(df.values)\n",
        "\n",
        "values = scaled\n",
        "\n",
        "split_percent = 0.80\n",
        "split = int(split_percent*len(values))\n",
        "\n",
        "look_back = 7\n",
        "\n",
        "train = values[:split]\n",
        "test = values[split:]\n",
        "\n",
        "date_train = df.index[:split]\n",
        "date_test = df.index[split:]\n",
        "date_prediction = df.index[split+look_back:]\n",
        "\n",
        "train_generator = TimeseriesGenerator(\n",
        "    train, train, length=look_back)\n",
        "test_generator = TimeseriesGenerator(\n",
        "    test, test, length=look_back)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(look_back, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mae')\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator, validation_data=test_generator, epochs=num_epochs,\n",
        "    shuffle=False, verbose=0)\n",
        "\n",
        "pyplot.plot(history.history['loss'], label='Training loss')\n",
        "pyplot.plot(history.history['val_loss'], label='Validation loss')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "\n",
        "prediction = model.predict(test_generator)\n",
        "\n",
        "train = scaler.inverse_transform(train).reshape(-1)\n",
        "test = scaler.inverse_transform(test).reshape(-1)\n",
        "prediction = scaler.inverse_transform(prediction).reshape(-1)\n",
        "\n",
        "data_trace = go.Scatter(x=date_train, y=train, mode='lines', name='Data')\n",
        "prediction_trace = go.Scatter(\n",
        "    x=date_prediction, y=prediction, mode='lines', name='Prediction')\n",
        "truth_trace = go.Scatter(\n",
        "    x=date_test, y=test, mode='lines', name='Ground Truth')\n",
        "layout = go.Layout(title=\"nuovi_positivi\", xaxis={\n",
        "                   'title': \"Date\"}, yaxis={'title': \"nuovi_positivi\"})\n",
        "\n",
        "fig = go.Figure(data=[data_trace, prediction_trace,\n",
        "                truth_trace], layout=layout)\n",
        "fig.show()\n",
        "\n",
        "# first seven steps used for lags\n",
        "# divided before series to supervised\n",
        "print('MAE: %.3f' % mean_absolute_error(test[look_back:], prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgb1Mg4StHbT"
      },
      "source": [
        "# Multivariate LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHiFkUcG4ZZK"
      },
      "outputs": [],
      "source": [
        "df = frame_interesting_columns\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(df)\n",
        "\n",
        "column_to_predict = 'nuovi_positivi'\n",
        "index_to_predict = df.columns.get_loc(column_to_predict)\n",
        "\n",
        "split_percent = 0.80\n",
        "split = int(split_percent*len(scaled))\n",
        "\n",
        "look_back = 7\n",
        "n_future = 1\n",
        "\n",
        "train = scaled[:split]\n",
        "test = scaled[split:]\n",
        "\n",
        "test_original = df[column_to_predict][split:].values\n",
        "\n",
        "date_train = df.index[:split]\n",
        "date_test = df.index[split:]\n",
        "date_prediction = df.index[split+look_back:]\n",
        "\n",
        "train_X, test_X = [], []\n",
        "train_y, test_y = [], []\n",
        "\n",
        "for i in range(look_back, len(train) - n_future + 1):\n",
        "    train_X.append(train[i - look_back:i, 0:train.shape[1]])\n",
        "    train_y.append(train[i + n_future - 1:i + n_future, index_to_predict])\n",
        "\n",
        "for i in range(look_back, len(test) - n_future + 1):\n",
        "    test_X.append(test[i - look_back:i, 0:test.shape[1]])\n",
        "    test_y.append(test[i + n_future - 1:i + n_future, index_to_predict])\n",
        "\n",
        "train_X, train_y = np.array(train_X), np.array(train_y)\n",
        "test_X, test_y = np.array(test_X), np.array(test_y)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(\n",
        "    train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history = model.fit(train_X, train_y, epochs=num_epochs,\n",
        "                    validation_data=(test_X, test_y), verbose=0,\n",
        "                    shuffle=False)\n",
        "\n",
        "pyplot.plot(history.history['loss'], label='Training loss')\n",
        "pyplot.plot(history.history['val_loss'], label='Validation loss')\n",
        "pyplot.legend()\n",
        "\n",
        "prediction = model.predict(test_X)\n",
        "\n",
        "prediction_copies = np.repeat(prediction, df.shape[1], axis=-1)\n",
        "test_y_copies = np.repeat(pd.DataFrame(test_y).values, df.shape[1], axis=-1)\n",
        "\n",
        "prediction_descaled = scaler.inverse_transform(prediction_copies)[:, 0]\n",
        "test_descaled = scaler.inverse_transform(test)[:, index_to_predict]\n",
        "test_y_descaled = scaler.inverse_transform(test_y_copies)[:, 0]\n",
        "\n",
        "train = scaler.inverse_transform(scaled)[:, index_to_predict].reshape(-1)\n",
        "test = test_descaled.reshape((-1))\n",
        "test_y = test_y_descaled.reshape((-1))\n",
        "prediction = prediction_descaled.reshape((-1))\n",
        "\n",
        "data_trace = go.Scatter(x=date_train, y=train, mode='lines', name='Data')\n",
        "prediction_trace = go.Scatter(\n",
        "    x=date_prediction, y=prediction, mode='lines', name='Prediction')\n",
        "truth_trace = go.Scatter(\n",
        "    x=date_test, y=test_original, mode='lines', name='Ground Truth')\n",
        "layout = go.Layout(title=\"nuovi_positivi\", xaxis={\n",
        "                   'title': \"Date\"}, yaxis={'title': \"nuovi_positivi\"})\n",
        "\n",
        "fig = go.Figure(data=[data_trace, prediction_trace,\n",
        "                truth_trace], layout=layout)\n",
        "fig.show()\n",
        "\n",
        "print('MAE: %.3f' % mean_absolute_error(test_original[look_back:], prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq4kerF4cyB3"
      },
      "source": [
        "# Multivariate LSTM with TimeseriesGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBBd_ev2t9-V"
      },
      "outputs": [],
      "source": [
        "df = frame_interesting_columns\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(df.values)\n",
        "\n",
        "values = scaled\n",
        "\n",
        "column_to_predict = 'nuovi_positivi'\n",
        "index_to_predict = df.columns.get_loc(column_to_predict)\n",
        "\n",
        "split_percent = 0.80\n",
        "split = int(split_percent*len(scaled))\n",
        "\n",
        "look_back = 7\n",
        "\n",
        "date_train = df.index[:split]\n",
        "date_test = df.index[split:]\n",
        "date_prediction = df.index[split+look_back:]\n",
        "\n",
        "test_original = df[column_to_predict][split:].values\n",
        "\n",
        "X = values[:][:]\n",
        "y = values[:, index_to_predict][:]\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(\n",
        "    X, y, test_size=0.20, shuffle=False)\n",
        "\n",
        "train_generator = TimeseriesGenerator(\n",
        "    train_X, train_y, sampling_rate=1, length=look_back)\n",
        "test_generator = TimeseriesGenerator(\n",
        "    test_X, test_y, sampling_rate=1, length=look_back)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(\n",
        "    look_back, scaled.shape[1]), return_sequences=True))\n",
        "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator, validation_data=test_generator, epochs=num_epochs,\n",
        "    shuffle=False, verbose=0)\n",
        "\n",
        "pyplot.plot(history.history['loss'], label='Training loss')\n",
        "pyplot.plot(history.history['val_loss'], label='Validation loss')\n",
        "pyplot.legend()\n",
        "\n",
        "prediction = model.predict(test_generator)\n",
        "\n",
        "prediction_copies = np.repeat(prediction, df.shape[1], axis=-1)\n",
        "test_copies = np.repeat(pd.DataFrame(test_y).values, df.shape[1], axis=-1)\n",
        "\n",
        "prediction_descaled = scaler.inverse_transform(prediction_copies)[:, 0]\n",
        "test_descaled = scaler.inverse_transform(test_copies)[:, 0]\n",
        "\n",
        "train = scaler.inverse_transform(values)[:, index_to_predict].reshape(-1)\n",
        "test = test_descaled.reshape((-1))\n",
        "prediction = prediction_descaled.reshape((-1))\n",
        "\n",
        "data_trace = go.Scatter(x=date_train, y=train, mode='lines', name='Data')\n",
        "prediction_trace = go.Scatter(\n",
        "    x=date_prediction, y=prediction, mode='lines', name='Prediction')\n",
        "truth_trace = go.Scatter(\n",
        "    x=date_test, y=test_original, mode='lines', name='Ground Truth')\n",
        "layout = go.Layout(title=\"nuovi_positivi\", xaxis={\n",
        "                   'title': \"Date\"}, yaxis={'title': \"nuovi_positivi\"})\n",
        "\n",
        "fig = go.Figure(data=[data_trace, prediction_trace,\n",
        "                truth_trace], layout=layout)\n",
        "fig.show()\n",
        "\n",
        "print('MAE: %.3f' % mean_absolute_error(test_original[look_back:], prediction))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "covid_forecasting.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b6e8a8e6cd5b0d8bd2b931e6e2bcfab8fa0bbcead3979137bf827a61abd923e3"
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 64-bit ('tf': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "metadata": {
      "interpreter": {
        "hash": "f85c0ae1067a86ad6a96b144378883e79fd1516474b579ba33ee3a7084540002"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
